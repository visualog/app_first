#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë™í–‰ë³µê¶Œ(ë¡œë˜6/45) ê³¼ê±° ë°ì´í„° 'ê³µì‹ í†µê³„ ì „ì²´' ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (Resume ì™„ì „ ì ìš© ë²„ì „)

âœ… Resume ë™ì‘
- lotto_full_history.csv ì— ì´ë¯¸ ì €ì¥ëœ ìµœëŒ€ 'íšŒì°¨'ë¥¼ ì½ì–´, ê·¸ ë‹¤ìŒ íšŒì°¨ë¶€í„° ìë™ ì¬ê°œ
- first_prize_shops_by_draw.csv ë„ ì´ë¯¸ ì €ì¥ëœ íšŒì°¨ë¥¼ ì½ì–´, ê·¸ ë‹¤ìŒ íšŒì°¨ë¶€í„° ìë™ ì¬ê°œ
- first_prize_shop_counts.csv ëŠ” (ìƒí˜¸,ì£¼ì†Œ) ê¸°ì¤€ ëˆ„ì  ì§‘ê³„ë¥¼ ì´ì–´ì„œ ê°±ì‹ 

ì¶œë ¥ íŒŒì¼
1) lotto_full_history.csv
2) first_prize_shops_by_draw.csv
3) first_prize_shop_counts.csv

ì‚¬ìš©
- pip install requests beautifulsoup4
- python collect_lotto_full_resume.py
"""

import csv
import os
import re
import time
from typing import Dict, Any, Optional, List, Tuple
from urllib.parse import quote

import requests
from bs4 import BeautifulSoup


# -----------------------------
# ì„¤ì •
# -----------------------------
API_URL = "https://www.dhlottery.co.kr/common.do"  # getLottoNumber
BYWIN_URL = "https://www.dhlottery.co.kr/gameResult.do?method=byWin"
TOPSTORE_PC_URL = "https://www.dhlottery.co.kr/store.do?method=topStore&pageGubun=L645"
TOPSTORE_M_URL = "https://m.dhlottery.co.kr/store.do?method=topStore&pageGubun=L645"

START_DRAW = 1
END_DRAW = None  # Noneì´ë©´ ìµœì‹  íšŒì°¨ ìë™ íƒìƒ‰

TIMEOUT_SEC = 10
MAX_RETRIES = 3
REQUEST_DELAY_SEC = 0.3

USER_AGENT = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36"
)

OUT_FULL = "lotto_full_history.csv"
OUT_SHOPS_BY_DRAW = "first_prize_shops_by_draw.csv"
OUT_SHOP_COUNTS = "first_prize_shop_counts.csv"

FULL_HEADER = [
    "ì¶”ì²¨ì¼","íšŒì°¨","ë‹¹ì²¨ë²ˆí˜¸","ë³´ë„ˆìŠ¤ë²ˆí˜¸",
    "1ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡","1ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜","1ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡",
    "2ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡","2ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜","2ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡",
    "3ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡","3ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜","3ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡",
    "4ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡","4ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜","4ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡",
    "5ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡","5ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜","5ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡",
    "ìë™","ë°˜ìë™","ìˆ˜ë™",
    "ì´íŒë§¤ê¸ˆì•¡"
]

SHOPS_BY_DRAW_HEADER = ["íšŒì°¨","ë“±ìœ„","ìƒí˜¸","êµ¬ë¶„","ì£¼ì†Œ","êµ¬ê¸€ë§µë§í¬"]
SHOP_COUNTS_HEADER = ["ìƒí˜¸","ì£¼ì†Œ","1ë“±_ë°°ì¶œíšŸìˆ˜","êµ¬ê¸€ë§µë§í¬"]


# -----------------------------
# ìœ í‹¸
# -----------------------------
def ensure_csv(path: str, header: List[str]) -> None:
    if not os.path.exists(path):
        with open(path, "w", newline="", encoding="utf-8") as f:
            csv.writer(f).writerow(header)


def to_int(x: Any) -> int:
    if x is None:
        return 0
    s = re.sub(r"[^\d]", "", str(x))
    return int(s) if s else 0


def make_google_map_link(address: str) -> str:
    if not address:
        return ""
    return "https://www.google.com/maps/search/?api=1&query=" + quote(address)


def request_with_retry(session: requests.Session, url: str, params: Dict[str, Any]) -> Optional[requests.Response]:
    headers = {"User-Agent": USER_AGENT}
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            r = session.get(url, params=params, timeout=TIMEOUT_SEC, headers=headers)
            r.raise_for_status()
            return r
        except Exception as e:
            if attempt == MAX_RETRIES:
                print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {url} params={params} err={e}")
                return None
            time.sleep(0.5 * attempt)
    return None


def norm_key(name: str, addr: str) -> Tuple[str, str]:
    n = re.sub(r"\s+", " ", (name or "").strip())
    a = re.sub(r"\s+", " ", (addr or "").strip())
    return (n, a)


def get_last_saved_draw_from_full(csv_path: str) -> int:
    """lotto_full_history.csv ì—ì„œ ìµœëŒ€ íšŒì°¨ë¥¼ ì½ìŒ."""
    if not os.path.exists(csv_path):
        return 0
    last = 0
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        if not reader.fieldnames:
            return 0
        # 'íšŒì°¨' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¬ê°œ ë¶ˆê°€
        if "íšŒì°¨" not in reader.fieldnames:
            return 0
        for row in reader:
            try:
                last = max(last, int(str(row.get("íšŒì°¨", "")).replace("íšŒ", "").strip()))
            except Exception:
                continue
    return last


def get_last_saved_draw_from_shops(csv_path: str) -> int:
    """first_prize_shops_by_draw.csv ì—ì„œ ìµœëŒ€ íšŒì°¨ë¥¼ ì½ìŒ."""
    if not os.path.exists(csv_path):
        return 0
    last = 0
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        if not reader.fieldnames:
            return 0
        if "íšŒì°¨" not in reader.fieldnames:
            return 0
        for row in reader:
            try:
                last = max(last, int(str(row.get("íšŒì°¨", "")).replace("íšŒ", "").strip()))
            except Exception:
                continue
    return last


# -----------------------------
# 1) API: ë‹¹ì²¨ë²ˆí˜¸/1ë“±/íŒë§¤ê¸ˆì•¡
# -----------------------------
def fetch_api_draw(session: requests.Session, draw_no: int) -> Optional[Dict[str, Any]]:
    r = request_with_retry(session, API_URL, {"method": "getLottoNumber", "drwNo": draw_no})
    if not r:
        return None
    try:
        data = r.json()
    except Exception:
        return None
    if data.get("returnValue") != "success":
        return None
    return data


def find_latest_draw(session: requests.Session, start_hint: int = 1200) -> int:
    """APIë¥¼ ì´ìš©í•´ ìµœì‹  íšŒì°¨ë¥¼ ë¹ ë¥´ê²Œ ì°¾ìŒ(ì§€ìˆ˜ ì¦ê°€ + ì´ë¶„ íƒìƒ‰)."""
    lo = max(1, int(start_hint))
    if fetch_api_draw(session, lo) is None:
        lo = 1
        if fetch_api_draw(session, lo) is None:
            return 0

    step = 1
    hi = lo
    while True:
        cand = hi + step
        ok = fetch_api_draw(session, cand) is not None
        time.sleep(REQUEST_DELAY_SEC)
        if not ok:
            hi = cand
            break
        hi = cand
        step *= 2

    left = max(1, hi - step)
    right = hi
    last_success = left

    while left > 1 and fetch_api_draw(session, left) is None:
        left = max(1, left - step)
        time.sleep(REQUEST_DELAY_SEC)

    while left <= right:
        mid = (left + right) // 2
        ok = fetch_api_draw(session, mid) is not None
        time.sleep(REQUEST_DELAY_SEC)
        if ok:
            last_success = mid
            left = mid + 1
        else:
            right = mid - 1

    return last_success


# -----------------------------
# 2) byWin: 1~5ë“± + ìë™/ë°˜ìë™/ìˆ˜ë™
# -----------------------------
def parse_bywin(session: requests.Session, draw_no: int) -> Dict[str, Any]:
    r = request_with_retry(session, BYWIN_URL, {"drwNo": draw_no})
    if not r:
        return {}

    soup = BeautifulSoup(r.text, "html.parser")
    result: Dict[str, Any] = {}

    prize_table = None
    for t in soup.find_all("table"):
        th_text = " ".join(th.get_text(" ", strip=True) for th in t.find_all("th"))
        if (("ë“±ìœ„" in th_text) or ("ìˆœìœ„" in th_text)) and (("ì´ë‹¹ì²¨ê¸ˆì•¡" in th_text) or ("ë‹¹ì²¨ê¸ˆì•¡" in th_text)):
            prize_table = t
            break

    if prize_table:
        rows = (prize_table.find("tbody").find_all("tr") if prize_table.find("tbody") else prize_table.find_all("tr"))
        for row in rows:
            cols = [c.get_text(" ", strip=True) for c in row.find_all(["td", "th"])]
            if len(cols) < 4:
                continue
            m = re.search(r"([1-5])", cols[0])
            if not m:
                continue
            k = int(m.group(1))
            result[f"{k}ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡"] = to_int(cols[1])
            result[f"{k}ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜"] = to_int(cols[2])
            result[f"{k}ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡"] = to_int(cols[3])

    text = soup.get_text("\n", strip=True)
    auto = semi = manual = None

    for line in text.splitlines():
        if ("ìë™" in line) and ("ìˆ˜ë™" in line) and ("ë°˜ìë™" in line):
            a = re.search(r"ìë™\s*([0-9,]+)", line)
            s = re.search(r"ë°˜ìë™\s*([0-9,]+)", line)
            m = re.search(r"ìˆ˜ë™\s*([0-9,]+)", line)
            if a and s and m:
                auto, semi, manual = to_int(a.group(1)), to_int(s.group(1)), to_int(m.group(1))
                break

    if auto is None or semi is None or manual is None:
        for t in soup.find_all("table"):
            t_text = t.get_text(" ", strip=True)
            if ("ìë™" in t_text) and ("ìˆ˜ë™" in t_text) and ("ë°˜ìë™" in t_text):
                tds = [td.get_text(" ", strip=True) for td in t.find_all("td")]
                joined = " | ".join(tds)
                a = re.search(r"ìë™\s*\|\s*([0-9,]+)", joined)
                s = re.search(r"ë°˜ìë™\s*\|\s*([0-9,]+)", joined)
                m = re.search(r"ìˆ˜ë™\s*\|\s*([0-9,]+)", joined)
                if a and s and m:
                    auto, semi, manual = to_int(a.group(1)), to_int(s.group(1)), to_int(m.group(1))
                    break

    result["ìë™"] = "" if auto is None else auto
    result["ë°˜ìë™"] = "" if semi is None else semi
    result["ìˆ˜ë™"] = "" if manual is None else manual

    return result


# -----------------------------
# 3) 1ë“± ë°°ì¶œì : topStore
# -----------------------------
def parse_topstore_html(html: str, draw_no: int) -> List[Dict[str, Any]]:
    soup = BeautifulSoup(html, "html.parser")

    target = None
    for t in soup.find_all("table"):
        th_text = " ".join(th.get_text(" ", strip=True) for th in t.find_all("th"))
        if (("ìƒí˜¸" in th_text) or ("ìƒí˜¸ëª…" in th_text)) and ("êµ¬ë¶„" in th_text) and (("ì†Œì¬ì§€" in th_text) or ("ì£¼ì†Œ" in th_text)):
            target = t
            break

    if not target:
        return []

    body = target.find("tbody") or target
    rows = body.find_all("tr")

    shops: List[Dict[str, Any]] = []
    for row in rows:
        cols = [c.get_text(" ", strip=True) for c in row.find_all("td")]
        if len(cols) < 3:
            continue

        if len(cols) >= 4:
            name = cols[1]
            mode = cols[2]
            addr = cols[3]
        else:
            name, mode, addr = cols[0], cols[1], cols[2]

        shops.append({
            "íšŒì°¨": draw_no,
            "ë“±ìœ„": 1,
            "ìƒí˜¸": name,
            "êµ¬ë¶„": mode,
            "ì£¼ì†Œ": addr,
            "êµ¬ê¸€ë§µë§í¬": make_google_map_link(addr),
        })

    return shops


def fetch_first_prize_shops(session: requests.Session, draw_no: int) -> List[Dict[str, Any]]:
    r = request_with_retry(session, TOPSTORE_M_URL, {"method": "topStore", "pageGubun": "L645", "drwNo": draw_no})
    if r:
        shops = parse_topstore_html(r.text, draw_no)
        if shops:
            return shops

    r2 = request_with_retry(session, TOPSTORE_PC_URL, {"method": "topStore", "pageGubun": "L645", "drwNo": draw_no})
    if r2:
        return parse_topstore_html(r2.text, draw_no)

    return []


# -----------------------------
# ë©”ì¸ ìˆ˜ì§‘
# -----------------------------
def collect(start_draw: int = START_DRAW, end_draw: Optional[int] = END_DRAW) -> None:
    ensure_csv(OUT_FULL, FULL_HEADER)
    ensure_csv(OUT_SHOPS_BY_DRAW, SHOPS_BY_DRAW_HEADER)

    # Resume: ì´ë¯¸ ì €ì¥ëœ ë§ˆì§€ë§‰ íšŒì°¨ë¥¼ ì½ì–´ì„œ start_drawë¥¼ ìë™ ì¡°ì •
    last_full = get_last_saved_draw_from_full(OUT_FULL)
    last_shops = get_last_saved_draw_from_shops(OUT_SHOPS_BY_DRAW)

    last_saved = max(last_full, last_shops)
    if last_saved > 0:
        start_draw = max(int(start_draw), last_saved + 1)
        print(f"ğŸ” Resume: ì´ë¯¸ {last_saved}íšŒê¹Œì§€ ì €ì¥ë¨ â†’ {start_draw}íšŒë¶€í„° ì¬ê°œ")

    shop_counts: Dict[Tuple[str, str], int] = {}

    # ëˆ„ì  ì§‘ê³„ ì´ì–´ê°€ê¸°
    if os.path.exists(OUT_SHOP_COUNTS):
        with open(OUT_SHOP_COUNTS, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                key = norm_key(row.get("ìƒí˜¸", ""), row.get("ì£¼ì†Œ", ""))
                shop_counts[key] = int(row.get("1ë“±_ë°°ì¶œíšŸìˆ˜", "0") or 0)

    with requests.Session() as session:
        if end_draw is None:
            end_draw = find_latest_draw(session, start_hint=max(1200, last_saved))
            print(f"ğŸ” ìµœì‹  íšŒì°¨(ìë™ íƒìƒ‰): {end_draw}")

        if start_draw > end_draw:
            print(f"âœ… ì´ë¯¸ ìµœì‹ ({end_draw}íšŒ)ê¹Œì§€ ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        for draw_no in range(int(start_draw), int(end_draw) + 1):
            api = fetch_api_draw(session, draw_no)
            time.sleep(REQUEST_DELAY_SEC)

            if not api:
                print(f"âš ï¸ API ì‹¤íŒ¨: {draw_no}íšŒ")
                continue

            base = {
                "ì¶”ì²¨ì¼": api.get("drwNoDate", ""),
                "íšŒì°¨": draw_no,
                "ë‹¹ì²¨ë²ˆí˜¸": ",".join(str(api.get(f"drwtNo{i}", "")) for i in range(1, 7)),
                "ë³´ë„ˆìŠ¤ë²ˆí˜¸": api.get("bnusNo", ""),
                "1ë“±_ì´ë‹¹ì²¨ê¸ˆì•¡": to_int(api.get("firstAccumamnt", 0)),
                "1ë“±_ë‹¹ì²¨ê²Œì„ìˆ˜": to_int(api.get("firstPrzwnerCo", 0)),
                "1ë“±_1ê²Œì„ë‹¹ë‹¹ì²¨ê¸ˆì•¡": to_int(api.get("firstWinamnt", 0)),
                "ì´íŒë§¤ê¸ˆì•¡": to_int(api.get("totSellamnt", 0)),
            }

            bywin = parse_bywin(session, draw_no)
            time.sleep(REQUEST_DELAY_SEC)

            full_row = {h: "" for h in FULL_HEADER}
            full_row.update(base)
            full_row.update(bywin)

            with open(OUT_FULL, "a", newline="", encoding="utf-8") as f:
                w = csv.DictWriter(f, fieldnames=FULL_HEADER)
                w.writerow(full_row)

            shops = fetch_first_prize_shops(session, draw_no)
            time.sleep(REQUEST_DELAY_SEC)

            if shops:
                with open(OUT_SHOPS_BY_DRAW, "a", newline="", encoding="utf-8") as f:
                    w = csv.DictWriter(f, fieldnames=SHOPS_BY_DRAW_HEADER)
                    for s in shops:
                        w.writerow(s)
                        key = norm_key(s["ìƒí˜¸"], s["ì£¼ì†Œ"])
                        shop_counts[key] = shop_counts.get(key, 0) + 1

            print(f"âœ… {draw_no}íšŒ ìˆ˜ì§‘ ì™„ë£Œ (1ë“± ë°°ì¶œì  {len(shops)}ê³³)")

    with open(OUT_SHOP_COUNTS, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=SHOP_COUNTS_HEADER)
        w.writeheader()
        for (name, addr), cnt in sorted(shop_counts.items(), key=lambda x: x[1], reverse=True):
            w.writerow({
                "ìƒí˜¸": name,
                "ì£¼ì†Œ": addr,
                "1ë“±_ë°°ì¶œíšŸìˆ˜": cnt,
                "êµ¬ê¸€ë§µë§í¬": make_google_map_link(addr),
            })

    print("ğŸ‰ ì™„ë£Œ!")
    print(f"- íšŒì°¨ë³„ í†µê³„: {OUT_FULL}")
    print(f"- íšŒì°¨ë³„ 1ë“± ë°°ì¶œì : {OUT_SHOPS_BY_DRAW}")
    print(f"- 1ë“± ë°°ì¶œì  ëˆ„ì : {OUT_SHOP_COUNTS}")


if __name__ == "__main__":
    collect()
